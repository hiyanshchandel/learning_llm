{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ab332f",
   "metadata": {},
   "source": [
    "## TOKEN EMBEDDINGS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffea184",
   "metadata": {},
   "source": [
    "![Screenshot](images/screenshot1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d0f85",
   "metadata": {},
   "source": [
    "a well trained embedding can capture significant syntactical information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19969981",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Let's illustrate how the token ID to embedding vector conversion works with a hands-on\n",
    "example. Suppose we have the following four input tokens with IDs 2, 3, 5, and 1:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952d6baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.588337Z",
     "iopub.status.busy": "2025-06-07T03:05:07.587588Z",
     "iopub.status.idle": "2025-06-07T03:05:07.591897Z",
     "shell.execute_reply": "2025-06-07T03:05:07.591278Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.588315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e47a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "For the sake of simplicity and illustration purposes, suppose we have a small vocabulary of\n",
    "only 6 words (instead of the 50,257 words in the BPE tokenizer vocabulary), and we want\n",
    "to create embeddings of size 3 (in GPT-3, the embedding size is 12,288 dimensions):\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ffae68",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Using the vocab_size and output_dim, we can instantiate an embedding layer in PyTorch,\n",
    "setting the random seed to 123 for reproducibility purposes:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb058f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.593400Z",
     "iopub.status.busy": "2025-06-07T03:05:07.593158Z",
     "iopub.status.idle": "2025-06-07T03:05:07.612908Z",
     "shell.execute_reply": "2025-06-07T03:05:07.612145Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.593380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 4\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e46182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.614250Z",
     "iopub.status.busy": "2025-06-07T03:05:07.613971Z",
     "iopub.status.idle": "2025-06-07T03:05:07.630701Z",
     "shell.execute_reply": "2025-06-07T03:05:07.629859Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.614227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880],\n",
       "        [ 0.3486,  0.6603, -0.2196, -0.3792],\n",
       "        [-0.1606, -0.4015,  0.6957, -1.8061],\n",
       "        [ 1.8960, -0.1750,  1.3689, -1.6033],\n",
       "        [-0.7849, -1.4096, -0.4076,  0.7953],\n",
       "        [ 0.9985,  0.2212,  1.8319, -0.3378]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b4bea",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "We can see that the weight matrix of the embedding layer contains small, random values.\n",
    "These values are optimized during LLM training as part of the LLM optimization itself, as we\n",
    "will see in upcoming chapters. Moreover, we can see that the weight matrix has six rows\n",
    "and three columns. There is one row for each of the six possible tokens in the vocabulary.\n",
    "And there is one column for each of the three embedding dimensions.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9df96b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "After we instantiated the embedding layer, let's now apply it to a token ID to obtain the\n",
    "embedding vector:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff52f679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.632230Z",
     "iopub.status.busy": "2025-06-07T03:05:07.631851Z",
     "iopub.status.idle": "2025-06-07T03:05:07.648447Z",
     "shell.execute_reply": "2025-06-07T03:05:07.647835Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.632214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8960, -0.1750,  1.3689, -1.6033]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.tensor([3])) # 4ht row of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d05549",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "each row in the embedding matrix is just an lookup to the token ids\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9975a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.649447Z",
     "iopub.status.busy": "2025-06-07T03:05:07.649191Z",
     "iopub.status.idle": "2025-06-07T03:05:07.666788Z",
     "shell.execute_reply": "2025-06-07T03:05:07.666083Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.649431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c456f66",
   "metadata": {},
   "source": [
    "![Screenshot](images/screenshot4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f39fd",
   "metadata": {},
   "source": [
    "this is after sinosuindal encoding, pick and 2 words which are close you'll see that most of the vector is same and for any two vectroo far away from each other the vectors are differnt , thus this is captuirinmg the relative positions pretty good, also if you see absolute positions of words are also captures in this as first word and last word are quite different (pick a line horizontally it represents positional encoding vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1979b",
   "metadata": {},
   "source": [
    "![Screenshot](images/screenshot5.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b8616",
   "metadata": {},
   "source": [
    "**POSITIONAL EMBEDDINGS (ENCODING WORD POSITIONS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0349bc2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.668320Z",
     "iopub.status.busy": "2025-06-07T03:05:07.667981Z",
     "iopub.status.idle": "2025-06-07T03:05:07.684843Z",
     "shell.execute_reply": "2025-06-07T03:05:07.683992Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.668291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import tiktoken\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b61be80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.685981Z",
     "iopub.status.busy": "2025-06-07T03:05:07.685731Z",
     "iopub.status.idle": "2025-06-07T03:05:07.703738Z",
     "shell.execute_reply": "2025-06-07T03:05:07.702991Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.685960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        #using sliding window to ceate input and target pairs\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i: i + max_length]\n",
    "            target_chunk = token_ids[i+1: max_length + 1 + i]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2808f243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.704829Z",
     "iopub.status.busy": "2025-06-07T03:05:07.704532Z",
     "iopub.status.idle": "2025-06-07T03:05:07.730319Z",
     "shell.execute_reply": "2025-06-07T03:05:07.729668Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.704805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        pre_processed = re.split(r'([,.:;\"!?()\\'_]|--|\\s)', text)   \n",
    "        pre_processed = [item for item in pre_processed if item.strip()]\n",
    "        pre_processed = [item if item in self.str_to_int else \"<|unk|>\" for item in pre_processed]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in pre_processed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9de25085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.738586Z",
     "iopub.status.busy": "2025-06-07T03:05:07.738370Z",
     "iopub.status.idle": "2025-06-07T03:05:07.751525Z",
     "shell.execute_reply": "2025-06-07T03:05:07.750971Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.738571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85c3cc70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.752930Z",
     "iopub.status.busy": "2025-06-07T03:05:07.752673Z",
     "iopub.status.idle": "2025-06-07T03:05:07.906552Z",
     "shell.execute_reply": "2025-06-07T03:05:07.905897Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.752908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d7adde2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.907374Z",
     "iopub.status.busy": "2025-06-07T03:05:07.907184Z",
     "iopub.status.idle": "2025-06-07T03:05:07.914177Z",
     "shell.execute_reply": "2025-06-07T03:05:07.913348Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.907358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/datase/wharton_verdict.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d921e5d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:07.915461Z",
     "iopub.status.busy": "2025-06-07T03:05:07.915201Z",
     "iopub.status.idle": "2025-06-07T03:05:08.829745Z",
     "shell.execute_reply": "2025-06-07T03:05:08.829171Z",
     "shell.execute_reply.started": "2025-06-07T03:05:07.915435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size = 8,\n",
    "                                  max_length = max_length, stride = 2,\n",
    "                                  shuffle = True)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets  = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4235a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.831665Z",
     "iopub.status.busy": "2025-06-07T03:05:08.831417Z",
     "iopub.status.idle": "2025-06-07T03:05:08.837276Z",
     "shell.execute_reply": "2025-06-07T03:05:08.836603Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.831648Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[  257,  1207,  8344,   803],\n",
      "        [  625,   262, 24818,   417],\n",
      "        [  257,  6487,    13,   366],\n",
      "        [  198,  1544, 13818,  4622],\n",
      "        [35569,   502,    13,   887],\n",
      "        [  683,    11, 10597,   314],\n",
      "        [  198,  1870,   465,  8216],\n",
      "        [  198,   265,  6384,  1456]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffb0d549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.838084Z",
     "iopub.status.busy": "2025-06-07T03:05:08.837870Z",
     "iopub.status.idle": "2025-06-07T03:05:08.855511Z",
     "shell.execute_reply": "2025-06-07T03:05:08.854707Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.838069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token Embeddings:\n",
      " torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"\\nToken Embeddings:\\n\", token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f523449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.856490Z",
     "iopub.status.busy": "2025-06-07T03:05:08.856283Z",
     "iopub.status.idle": "2025-06-07T03:05:08.872649Z",
     "shell.execute_reply": "2025-06-07T03:05:08.871944Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.856476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28eddb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.873610Z",
     "iopub.status.busy": "2025-06-07T03:05:08.873413Z",
     "iopub.status.idle": "2025-06-07T03:05:08.899580Z",
     "shell.execute_reply": "2025-06-07T03:05:08.898729Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.873595Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "792eaec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.900973Z",
     "iopub.status.busy": "2025-06-07T03:05:08.900677Z",
     "iopub.status.idle": "2025-06-07T03:05:08.913603Z",
     "shell.execute_reply": "2025-06-07T03:05:08.912941Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.900951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cbf51",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "As shown in the preceding code example, the input to the pos_embeddings is usually a\n",
    "placeholder vector torch.arange(context_length), which contains a sequence of\n",
    "numbers 0, 1, ..., up to the maximum input length âˆ’ 1. \n",
    "\n",
    "The context_length is a variable\n",
    "that represents the supported input size of the LLM. \n",
    "\n",
    "Here, we choose it similar to the\n",
    "maximum length of the input text. \n",
    "\n",
    "In practice, input text can be longer than the supported\n",
    "context length, in which case we have to truncate the text.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea5ae9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "As we can see, the positional embedding tensor consists of four 256-dimensional vectors.\n",
    "We can now add these directly to the token embeddings, where PyTorch will add the 4x256-\n",
    "dimensional pos_embeddings tensor to each 4x256-dimensional token embedding tensor in\n",
    "each of the 8 batches:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5b75b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.914602Z",
     "iopub.status.busy": "2025-06-07T03:05:08.914312Z",
     "iopub.status.idle": "2025-06-07T03:05:08.919362Z",
     "shell.execute_reply": "2025-06-07T03:05:08.918615Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.914586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39297c36",
   "metadata": {},
   "source": [
    "## IMPLEMENTING A COMPACT SELF ATTENTION PYTHON CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c2f45c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.920291Z",
     "iopub.status.busy": "2025-06-07T03:05:08.920051Z",
     "iopub.status.idle": "2025-06-07T03:05:08.936016Z",
     "shell.execute_reply": "2025-06-07T03:05:08.935469Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.920275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_K = nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_V = nn.Parameter(torch.randn(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_K\n",
    "        queries = x @ self.W_Q\n",
    "        values = x @ self.W_V\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5 , dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ab1d396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:08.937248Z",
     "iopub.status.busy": "2025-06-07T03:05:08.936799Z",
     "iopub.status.idle": "2025-06-07T03:05:09.031840Z",
     "shell.execute_reply": "2025-06-07T03:05:09.031055Z",
     "shell.execute_reply.started": "2025-06-07T03:05:08.937231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7053, -0.5213,  0.7561, -1.1033,  0.0726],\n",
      "        [ 0.6443, -0.5202,  0.7027, -1.0369,  0.1176],\n",
      "        [ 0.6507, -0.5203,  0.7091, -1.0447,  0.1130],\n",
      "        [ 0.6933, -0.5269,  0.7448, -1.0918,  0.0881],\n",
      "        [ 0.7910, -0.5222,  0.8522, -1.2159,  0.0105],\n",
      "        [ 0.6292, -0.5259,  0.6801, -1.0142,  0.1349]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "torch.manual_seed(123) \n",
    "\n",
    "sa_v1 = SelfAttention_v1(3,5)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b62737c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.032983Z",
     "iopub.status.busy": "2025-06-07T03:05:09.032704Z",
     "iopub.status.idle": "2025-06-07T03:05:09.038827Z",
     "shell.execute_reply": "2025-06-07T03:05:09.038007Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.032959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_K = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_V = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_K(x)\n",
    "        queries = self.W_Q(x)\n",
    "        values = self.W_V(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5 , dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb0fea03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.042194Z",
     "iopub.status.busy": "2025-06-07T03:05:09.041969Z",
     "iopub.status.idle": "2025-06-07T03:05:09.068803Z",
     "shell.execute_reply": "2025-06-07T03:05:09.067894Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.042177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v1 = SelfAttention_v2(3,2)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a7095",
   "metadata": {},
   "source": [
    "## HIDING FUTURE WORDS WITH CAUSAL ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1b20967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.070257Z",
     "iopub.status.busy": "2025-06-07T03:05:09.069953Z",
     "iopub.status.idle": "2025-06-07T03:05:09.078213Z",
     "shell.execute_reply": "2025-06-07T03:05:09.077387Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.070217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = inputs.shape[0]\n",
    "torch.triu(torch.ones(context_length, context_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d788eb",
   "metadata": {},
   "source": [
    "### IMPLEMENTING A COMPACT CAUSAL ATTENTION CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e309b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "In this section, we will now incorporate the causal attention and dropout modifications into\n",
    "the SelfAttention Python class we developed in section 3.4. \n",
    "\n",
    "This class will then serve as a\n",
    "template for developing multi-head attention in the upcoming section.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b611d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Before we begin, one more thing is to ensure that the code can handle batches\n",
    "consisting of more than one input. \n",
    "\n",
    "This will ensure that the CausalAttention class supports the batch\n",
    "outputs produced by the data loader we implemented earlier.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e96154",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "For simplicity, to simulate such batch inputs, we duplicate the input text example:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598e083",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    " 2 inputs with 6 tokens each, and each token has embedding dimension 3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65378ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.079424Z",
     "iopub.status.busy": "2025-06-07T03:05:09.079105Z",
     "iopub.status.idle": "2025-06-07T03:05:09.090782Z",
     "shell.execute_reply": "2025-06-07T03:05:09.090021Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.079399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    "                )\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84968b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.092010Z",
     "iopub.status.busy": "2025-06-07T03:05:09.091778Z",
     "iopub.status.idle": "2025-06-07T03:05:09.108682Z",
     "shell.execute_reply": "2025-06-07T03:05:09.107982Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.091993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CasualAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length,context_length),diagonal = 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens , d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf) \n",
    "        attn_weights = torch.softmax(attn_scores /keys.shape[-1]**0.5, dim = 1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7560ba2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.109734Z",
     "iopub.status.busy": "2025-06-07T03:05:09.109521Z",
     "iopub.status.idle": "2025-06-07T03:05:09.187604Z",
     "shell.execute_reply": "2025-06-07T03:05:09.186785Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.109710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0997,  0.1696, -0.0939],\n",
       "         [ 0.1442,  0.2287, -0.0623],\n",
       "         [ 0.1729,  0.2798, -0.0797],\n",
       "         [ 0.4581,  0.7070, -0.1655],\n",
       "         [ 0.2912,  0.4670, -0.1304],\n",
       "         [ 0.3052,  0.6786, -0.2947]],\n",
       "\n",
       "        [[ 0.0997,  0.1696, -0.0939],\n",
       "         [ 0.1081,  0.1840, -0.1018],\n",
       "         [ 0.4247,  0.6917, -0.2436],\n",
       "         [ 0.3148,  0.4797, -0.1037],\n",
       "         [-0.0170,  0.1707, -0.1731],\n",
       "         [ 0.3052,  0.6786, -0.2947]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CasualAttention(3, 3, context_length, dropout=0.5)\n",
    "context_vec = ca(batch)\n",
    "context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0613e4ff",
   "metadata": {},
   "source": [
    "## EXTENDING SINGLE HEAD ATTENTION TO STACKED ATTENTION (MULTIHEAD ATTENTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71eb2168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.188730Z",
     "iopub.status.busy": "2025-06-07T03:05:09.188512Z",
     "iopub.status.idle": "2025-06-07T03:05:09.192585Z",
     "shell.execute_reply": "2025-06-07T03:05:09.191973Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.188707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98264cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.193618Z",
     "iopub.status.busy": "2025-06-07T03:05:09.193263Z",
     "iopub.status.idle": "2025-06-07T03:05:09.216280Z",
     "shell.execute_reply": "2025-06-07T03:05:09.215531Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.193578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAtttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length,dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            CasualAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4653dbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.217266Z",
     "iopub.status.busy": "2025-06-07T03:05:09.217013Z",
     "iopub.status.idle": "2025-06-07T03:05:09.242527Z",
     "shell.execute_reply": "2025-06-07T03:05:09.241799Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.217249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0499,  0.0848, -0.0469,  0.0143,  0.0871,  0.0520],\n",
       "         [ 0.1262,  0.2064, -0.0820,  0.0101,  0.2142,  0.1086],\n",
       "         [ 0.2124,  0.3458, -0.1218,  0.0081,  0.3906,  0.1888],\n",
       "         [ 0.2885,  0.4546, -0.1387,  0.0028,  0.5420,  0.2603],\n",
       "         [ 0.2615,  0.5105, -0.2161,  0.0027,  0.7399,  0.3124],\n",
       "         [ 0.6519,  0.9957, -0.2431, -0.0180,  1.2439,  0.5864]],\n",
       "\n",
       "        [[ 0.0499,  0.0848, -0.0469,  0.0143,  0.0871,  0.0520],\n",
       "         [ 0.1262,  0.2064, -0.0820,  0.0101,  0.2142,  0.1086],\n",
       "         [ 0.2124,  0.3458, -0.1218,  0.0081,  0.3906,  0.1888],\n",
       "         [ 0.2885,  0.4546, -0.1387,  0.0028,  0.5420,  0.2603],\n",
       "         [ 0.2615,  0.5105, -0.2161,  0.0027,  0.7399,  0.3124],\n",
       "         [ 0.6519,  0.9957, -0.2431, -0.0180,  1.2439,  0.5864]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "mha = MultiHeadAtttentionWrapper(3, 3, context_length, dropout=0, num_heads = 2)\n",
    "context_vec = mha(batch)\n",
    "context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac42a33",
   "metadata": {},
   "source": [
    "### BATCHED STACKED MULTI HEADED ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a73a18e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.243877Z",
     "iopub.status.busy": "2025-06-07T03:05:09.243556Z",
     "iopub.status.idle": "2025-06-07T03:05:09.252673Z",
     "shell.execute_reply": "2025-06-07T03:05:09.252098Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.243860Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0) , \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.W_Value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # same as W_O\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens , d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_Value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1,2)\n",
    "        queries = queries.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim = -1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = (attn_weights @ values).transpose(1,2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c8e16",
   "metadata": {},
   "source": [
    "![Screenshot](images/screenshot6.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "464ca14c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.253623Z",
     "iopub.status.busy": "2025-06-07T03:05:09.253385Z",
     "iopub.status.idle": "2025-06-07T03:05:09.280061Z",
     "shell.execute_reply": "2025-06-07T03:05:09.279208Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.253600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 6])\n",
      "tensor([[[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],\n",
      "\n",
      "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Define the tensor with 3 rows and 6 columns\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89, 0.55, 0.87, 0.66],  # Row 1\n",
    "     [0.57, 0.85, 0.64, 0.22, 0.58, 0.33],  # Row 2\n",
    "     [0.77, 0.25, 0.10, 0.05, 0.80, 0.55]]  # Row 3\n",
    ")\n",
    "\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 6\n",
    "mha = MultiHeadedAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a7ec0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "For comparison, the smallest GPT-2 model (117 million parameters) has 12 attention\n",
    "heads and a context vector embedding size of 768. \n",
    "\n",
    "The largest GPT-2 model (1.5 billion\n",
    "parameters) has 25 attention heads and a context vector embedding size of 1600.\n",
    "\n",
    "Note\n",
    "that the embedding sizes of the token inputs and context embeddings are the same in GPT\n",
    "models (d_in = d_out).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053efc83",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 1: DUMMY GPT MODEL CLASS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf58d2f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Step 1: Use a placeholder for TransformerBlock\n",
    "\n",
    "Step 2: Use a placeholder for LayerNorm\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98f15783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.281322Z",
     "iopub.status.busy": "2025-06-07T03:05:09.280993Z",
     "iopub.status.idle": "2025-06-07T03:05:09.297944Z",
     "shell.execute_reply": "2025-06-07T03:05:09.297176Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.281296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73ff8cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.299134Z",
     "iopub.status.busy": "2025-06-07T03:05:09.298850Z",
     "iopub.status.idle": "2025-06-07T03:05:09.313615Z",
     "shell.execute_reply": "2025-06-07T03:05:09.312899Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.299111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg = GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccb83c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.314574Z",
     "iopub.status.busy": "2025-06-07T03:05:09.314353Z",
     "iopub.status.idle": "2025-06-07T03:05:09.329596Z",
     "shell.execute_reply": "2025-06-07T03:05:09.329003Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.314555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.dropout(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg): \n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20866762",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.331282Z",
     "iopub.status.busy": "2025-06-07T03:05:09.330541Z",
     "iopub.status.idle": "2025-06-07T03:05:09.351958Z",
     "shell.execute_reply": "2025-06-07T03:05:09.351286Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.331261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c966b88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:09.353020Z",
     "iopub.status.busy": "2025-06-07T03:05:09.352788Z",
     "iopub.status.idle": "2025-06-07T03:05:10.092273Z",
     "shell.execute_reply": "2025-06-07T03:05:10.091512Z",
     "shell.execute_reply.started": "2025-06-07T03:05:09.352995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0448,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6f9f5",
   "metadata": {},
   "source": [
    "## LAYER NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80a99f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.093498Z",
     "iopub.status.busy": "2025-06-07T03:05:10.093175Z",
     "iopub.status.idle": "2025-06-07T03:05:10.103896Z",
     "shell.execute_reply": "2025-06-07T03:05:10.103176Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.093481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38419a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The neural network layer we have coded consists of a Linear layer followed by a non-linear\n",
    "activation function, ReLU (short for Rectified Linear Unit), which is a standard activation\n",
    "function in neural networks. \n",
    "\n",
    "If you are unfamiliar with ReLU, it simply thresholds negative\n",
    "inputs to 0, ensuring that a layer outputs only positive values, which explains why the\n",
    "resulting layer output does not contain any negative values. \n",
    "\n",
    "(Note that we will use another,\n",
    "more sophisticated activation function in GPT, which we will introduce in the next section).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e7a81e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.105096Z",
     "iopub.status.busy": "2025-06-07T03:05:10.104811Z",
     "iopub.status.idle": "2025-06-07T03:05:10.134541Z",
     "shell.execute_reply": "2025-06-07T03:05:10.133918Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.105078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim = True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(mean)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7709636",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The first row in the mean tensor above contains the mean value for the first input row, and\n",
    "the second output row contains the mean for the second input row.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d92a06e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.135862Z",
     "iopub.status.busy": "2025-06-07T03:05:10.135364Z",
     "iopub.status.idle": "2025-06-07T03:05:10.150286Z",
     "shell.execute_reply": "2025-06-07T03:05:10.149393Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.135843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer output\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim = -1, keepdim = True)\n",
    "var = out_norm.var(dim = -1, keepdim = True)\n",
    "print(\"Normalized layer output\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0831a4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Note that the value 2.9802e-08 in the output tensor is the scientific notation for 2.9802 Ã—\n",
    "10-8, which is 0.0000000298 in decimal form. This value is very close to 0, but it is not\n",
    "exactly 0 due to small numerical errors that can accumulate because of the finite precision\n",
    "with which computers represent numbers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8af0f2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.151750Z",
     "iopub.status.busy": "2025-06-07T03:05:10.151091Z",
     "iopub.status.idle": "2025-06-07T03:05:10.158756Z",
     "shell.execute_reply": "2025-06-07T03:05:10.158217Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.151730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False)\n",
    "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03afd80a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "This specific implementation of layer Normalization operates on the last dimension of the\n",
    "input tensor x, which represents the embedding dimension (emb_dim). \n",
    "\n",
    "The variable eps is a\n",
    "small constant (epsilon) added to the variance to prevent division by zero during\n",
    "normalization. \n",
    "\n",
    "The scale and shift are two trainable parameters (of the same dimension\n",
    "as the input) that the LLM automatically adjusts during training if it is determined that\n",
    "doing so would improve the model's performance on its training task. \n",
    "\n",
    "This allows the model\n",
    "to learn appropriate scaling and shifting that best suit the data it is processing.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a11e0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "In our variance calculation method, we have opted for an implementation detail by\n",
    "setting unbiased=False. \n",
    "\n",
    "For those curious about what this means, in the variance\n",
    "calculation, we divide by the number of inputs n in the variance formula. \n",
    "\n",
    "This approach does not apply Bessel's correction, which typically uses n-1 instead of n in\n",
    "the denominator to adjust for bias in sample variance estimation. \n",
    "\n",
    "This decision results in a so-called biased estimate of the variance. \n",
    "\n",
    "For large-scale language\n",
    "models (LLMs), where the embedding dimension n is significantly large, the\n",
    "difference between using n and n-1 is practically negligible. \n",
    "\n",
    "We chose this approach to ensure compatibility with the GPT-2 model's normalization layers and because it\n",
    "reflects TensorFlow's default behavior, which was used to implement the original GPT2 model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c30075c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.159699Z",
     "iopub.status.busy": "2025-06-07T03:05:10.159442Z",
     "iopub.status.idle": "2025-06-07T03:05:10.181028Z",
     "shell.execute_reply": "2025-06-07T03:05:10.180169Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.159673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5528,  1.0693, -0.0223,  0.2656, -1.8654],\n",
      "        [ 0.9087, -1.3767, -0.9564,  1.1304,  0.2940]], grad_fn=<AddBackward0>)\n",
      "Mean:\n",
      " tensor([[-2.9802e-08],\n",
      "        [ 0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim = 5)\n",
    "out_ln  = ln(batch_example)\n",
    "print(out_ln)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81a5cb79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.182412Z",
     "iopub.status.busy": "2025-06-07T03:05:10.182033Z",
     "iopub.status.idle": "2025-06-07T03:05:10.196386Z",
     "shell.execute_reply": "2025-06-07T03:05:10.195826Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.182390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e01bb900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.197541Z",
     "iopub.status.busy": "2025-06-07T03:05:10.197054Z",
     "iopub.status.idle": "2025-06-07T03:05:10.778286Z",
     "shell.execute_reply": "2025-06-07T03:05:10.777463Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.197517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu, y_gelu_dist = gelu(x), relu(x), (gelu(x))/x\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu,y_gelu_dist], [\"GELU\", \"ReLU\", \"GELU_DIST\"]), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c365cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.779407Z",
     "iopub.status.busy": "2025-06-07T03:05:10.779143Z",
     "iopub.status.idle": "2025-06-07T03:05:10.783943Z",
     "shell.execute_reply": "2025-06-07T03:05:10.783407Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.779390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),    \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ef2300c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.784789Z",
     "iopub.status.busy": "2025-06-07T03:05:10.784611Z",
     "iopub.status.idle": "2025-06-07T03:05:10.853246Z",
     "shell.execute_reply": "2025-06-07T03:05:10.852456Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.784774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8338b9",
   "metadata": {},
   "source": [
    "# SHORTCUT CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b697c61",
   "metadata": {},
   "source": [
    "![Screenshot](images/screenshot7.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f747b73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.854410Z",
     "iopub.status.busy": "2025-06-07T03:05:10.854145Z",
     "iopub.status.idle": "2025-06-07T03:05:10.860359Z",
     "shell.execute_reply": "2025-06-07T03:05:10.859740Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.854385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e63ad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The code implements a deep neural network with 5 layers, each consisting of a Linear\n",
    "layer and a GELU activation function. \n",
    "\n",
    "In the forward pass, we iteratively pass the input\n",
    "through the layers and optionally add the shortcut connections  if\n",
    "the self.use_shortcut attribute is set to True.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850696e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Let's use this code to first initialize a neural network without shortcut connections. Here,\n",
    "each layer will be initialized such that it accepts an example with 3 input values and returns\n",
    "3 output values. The last layer returns a single output value:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb4932ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.861657Z",
     "iopub.status.busy": "2025-06-07T03:05:10.861142Z",
     "iopub.status.idle": "2025-06-07T03:05:10.880987Z",
     "shell.execute_reply": "2025-06-07T03:05:10.880460Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.861630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02063c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.881941Z",
     "iopub.status.busy": "2025-06-07T03:05:10.881684Z",
     "iopub.status.idle": "2025-06-07T03:05:10.895952Z",
     "shell.execute_reply": "2025-06-07T03:05:10.895408Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.881917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d59bd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "In the preceding code, we specify a loss function that computes how close the model output\n",
    "and a user-specified target (here, for simplicity, the value 0) are. \n",
    "\n",
    "Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model. \n",
    "\n",
    "We can iterate through the weight parameters via model.named_parameters(). \n",
    "\n",
    "Suppose we have a 3Ã—3 weight parameter matrix for a given layer. \n",
    "\n",
    "In that case, this layer will have 3Ã—3 gradient values, and we print the mean absolute gradient of these 3Ã—3 gradient values to\n",
    "obtain a single gradient value per layer to compare the gradients between layers more\n",
    "easily.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fd40f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "In short, the .backward() method is a convenient method in PyTorch that computes loss\n",
    "gradients, which are required during model training, without implementing the math for the\n",
    "gradient calculation ourselves, thereby making working with deep neural networks much\n",
    "more accessible. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9b839",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Let's now use the print_gradients function and apply it to the model without skip\n",
    "connections:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cdca392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:10.901842Z",
     "iopub.status.busy": "2025-06-07T03:05:10.901633Z",
     "iopub.status.idle": "2025-06-07T03:05:11.037769Z",
     "shell.execute_reply": "2025-06-07T03:05:11.037107Z",
     "shell.execute_reply.started": "2025-06-07T03:05:10.901827Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed95d82",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "As we can see based on the output of the print_gradients function, the gradients become\n",
    "smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which\n",
    "is a phenomenon called the vanishing gradient problem.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa92b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let's now instantiate a model with skip connections and see how it compares:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7194e3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:11.038822Z",
     "iopub.status.busy": "2025-06-07T03:05:11.038534Z",
     "iopub.status.idle": "2025-06-07T03:05:11.049357Z",
     "shell.execute_reply": "2025-06-07T03:05:11.048620Z",
     "shell.execute_reply.started": "2025-06-07T03:05:11.038797Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694108307361603\n",
      "layers.2.0.weight has gradient mean of 0.3289699852466583\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a1472",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "As we can see, based on the output, the last layer (layers.4) still has a larger gradient\n",
    "than the other layers. \n",
    "\n",
    "However, the gradient value stabilizes as we progress towards the\n",
    "first layer (layers.0) and doesn't shrink to a vanishingly small value.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd87349",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "In conclusion, shortcut connections are important for overcoming the limitations posed\n",
    "by the vanishing gradient problem in deep neural networks. \n",
    "\n",
    "Shortcut connections are a core building block of very large models such as LLMs, and they will help facilitate more effective\n",
    "training by ensuring consistent gradient flow across layers when we train the GPT model \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0355764",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cdc2221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:11.050676Z",
     "iopub.status.busy": "2025-06-07T03:05:11.050353Z",
     "iopub.status.idle": "2025-06-07T03:05:11.063220Z",
     "shell.execute_reply": "2025-06-07T03:05:11.062597Z",
     "shell.execute_reply.started": "2025-06-07T03:05:11.050658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False)\n",
    "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),    \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aef78877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:11.064346Z",
     "iopub.status.busy": "2025-06-07T03:05:11.063968Z",
     "iopub.status.idle": "2025-06-07T03:05:11.084043Z",
     "shell.execute_reply": "2025-06-07T03:05:11.083423Z",
     "shell.execute_reply.started": "2025-06-07T03:05:11.064318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransofrmerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadedAttention(\n",
    "            cfg[\"emb_dim\"], cfg[\"emb_dim\"], cfg[\"context_length\"],\n",
    "            cfg[\"drop_rate\"], cfg[\"n_heads\"], qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward (self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268da556",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Layer normalization (LayerNorm) is applied before each of these two components, and\n",
    "dropout is applied after them to regularize the model and prevent overfitting. \n",
    "\n",
    "This is also known as Pre-LayerNorm. \n",
    "\n",
    "Older architectures, such as the original transformer model,\n",
    "applied layer normalization after the self-attention and feed-forward networks instead,\n",
    "known as Post-LayerNorm, which often leads to worse training dynamics.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b3de627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:11.085207Z",
     "iopub.status.busy": "2025-06-07T03:05:11.084933Z",
     "iopub.status.idle": "2025-06-07T03:05:11.183716Z",
     "shell.execute_reply": "2025-06-07T03:05:11.183029Z",
     "shell.execute_reply.started": "2025-06-07T03:05:11.085186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransofrmerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db003c40",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As we can see from the code output, the transformer block maintains the input dimensions\n",
    "in its output, indicating that the transformer architecture processes sequences of data\n",
    "without altering their shape throughout the network.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b11ebb9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "The preservation of shape throughout the transformer block architecture is not incidental\n",
    "but a crucial aspect of its design. \n",
    "\n",
    "This design enables its effective application across a wide\n",
    "range of sequence-to-sequence tasks, where each output vector directly corresponds to an\n",
    "input vector, maintaining a one-to-one relationship. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69f799",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "However, the output is a context vector\n",
    "that encapsulates information from the entire input sequence.\n",
    "\n",
    "This means that while the physical dimensions of the sequence (length and feature size)\n",
    "remain unchanged as it passes through the transformer block, the content of each output\n",
    "vector is re-encoded to integrate contextual information from across the entire input\n",
    "sequence.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403551c2",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941cd900",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The device setting will allow us to train the model on a CPU or GPU, depending on which device the input\n",
    "data sits\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b28e6882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:11.184808Z",
     "iopub.status.busy": "2025-06-07T03:05:11.184522Z",
     "iopub.status.idle": "2025-06-07T03:05:11.191675Z",
     "shell.execute_reply": "2025-06-07T03:05:11.190815Z",
     "shell.execute_reply.started": "2025-06-07T03:05:11.184781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tok_emb  = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransofrmerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef2fb85e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:11.192988Z",
     "iopub.status.busy": "2025-06-07T03:05:11.192604Z",
     "iopub.status.idle": "2025-06-07T03:05:12.782747Z",
     "shell.execute_reply": "2025-06-07T03:05:12.782000Z",
     "shell.execute_reply.started": "2025-06-07T03:05:11.192965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76e164",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As we can see, the output tensor has the shape [2, 4, 50257], since we passed in 2 input\n",
    "texts with 4 tokens each. The last dimension, 50,257, corresponds to the vocabulary size of\n",
    "the tokenizer. In the next section, we will see how to convert each of these 50,257-\n",
    "dimensional output vectors back into tokens.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b134d41",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Using the numel() method, short for \"number of elements,\" we can collect the total\n",
    "number of parameters in the model's parameter tensors:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b25de605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:12.783744Z",
     "iopub.status.busy": "2025-06-07T03:05:12.783536Z",
     "iopub.status.idle": "2025-06-07T03:05:12.788944Z",
     "shell.execute_reply": "2025-06-07T03:05:12.788003Z",
     "shell.execute_reply.started": "2025-06-07T03:05:12.783729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011a00b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Earlier, we spoke of initializing a 124\n",
    "million parameter GPT model, so why is the actual number of parameters 163 million, as\n",
    "shown in the preceding code output?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3235865",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "The reason is a concept called weight tying that is used in the original GPT-2\n",
    "architecture, which means that the original GPT-2 architecture is reusing the weights from\n",
    "the token embedding layer in its output layer. \n",
    "\n",
    "To understand what this means, let's take a\n",
    "look at the shapes of the token embedding layer and linear output layer that we initialized\n",
    "on the model via the GPTModel earlier:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7cfbf2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:12.789936Z",
     "iopub.status.busy": "2025-06-07T03:05:12.789735Z",
     "iopub.status.idle": "2025-06-07T03:05:12.806818Z",
     "shell.execute_reply": "2025-06-07T03:05:12.806076Z",
     "shell.execute_reply.started": "2025-06-07T03:05:12.789921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed42f56",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As we can see based on the print outputs, the weight tensors for both these layers have the\n",
    "same shape:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350bb954",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The token embedding and output layers are very large due to the number of rows for the\n",
    "50,257 in the tokenizer's vocabulary. Let's remove the output layer parameter count from\n",
    "the total GPT-2 model count according to the weight tying:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38117b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:12.807864Z",
     "iopub.status.busy": "2025-06-07T03:05:12.807616Z",
     "iopub.status.idle": "2025-06-07T03:05:12.825731Z",
     "shell.execute_reply": "2025-06-07T03:05:12.825167Z",
     "shell.execute_reply.started": "2025-06-07T03:05:12.807842Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151f226",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As we can see, the model is now only 124 million parameters large, matching the original\n",
    "size of the GPT-2 model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7752dd4b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "Weight tying reduces the overall memory footprint and computational complexity of the\n",
    "model. However, in my experience, using separate token embedding and output layers\n",
    "results in better training and model performance; hence, we are using separate layers in\n",
    "our GPTModel implementation. The same is true for modern LLMs.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3397b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Lastly, let us compute the memory requirements of the 163 million parameters in our\n",
    "GPTModel object:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4c8f883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:12.826343Z",
     "iopub.status.busy": "2025-06-07T03:05:12.826184Z",
     "iopub.status.idle": "2025-06-07T03:05:12.842414Z",
     "shell.execute_reply": "2025-06-07T03:05:12.841803Z",
     "shell.execute_reply.started": "2025-06-07T03:05:12.826330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e640d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "In conclusion, by calculating the memory requirements for the 163 million parameters in\n",
    "our GPTModel object and assuming each parameter is a 32-bit float taking up 4 bytes, we\n",
    "find that the total size of the model amounts to 621.83 MB, illustrating the relatively large\n",
    "storage capacity required to accommodate even relatively small LLMs.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f28e64",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "In this section, we implemented the GPTModel architecture and saw that it outputs\n",
    "numeric tensors of shape [batch_size, num_tokens, vocab_size]. In the next section,\n",
    "we will write the code to convert these output tensors into text.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf9a9d",
   "metadata": {},
   "source": [
    "Weight tying means sharing the same weight matrix between:\n",
    "\n",
    "The token embedding layer (converts token IDs to vectors), and\n",
    "\n",
    "The output projection layer (converts final vectors to logits over the vocabulary).\n",
    "\n",
    "So instead of having two separate matrices:\n",
    "\n",
    "E for input embedding: shape [vocab_size, emb_dim]\n",
    "\n",
    "W for output projection: shape [emb_dim, vocab_size]\n",
    "\n",
    "We reuse E.T as the output layer:\n",
    "\n",
    "logits = x @ E.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e34fb",
   "metadata": {},
   "source": [
    " Why Use Weight Tying?\n",
    "Fewer Parameters\n",
    "\n",
    "GPT-2 has a huge vocabulary (e.g., 50,000 tokens). Instead of storing two large matrices, weight tying saves memory.\n",
    "\n",
    "Improved Generalization\n",
    "\n",
    "Sharing weights forces the model to treat input and output tokens in a more consistent way.\n",
    "\n",
    "This helps especially in language modeling, where the same vocabulary is used at both ends.\n",
    "\n",
    "Empirical Gains\n",
    "\n",
    "Papers like \"Using the Output Embedding to Improve Language Models\" (Press & Wolf, 2017) showed that weight tying improves perplexity.\n",
    "\n",
    "ðŸ§  Intuition\n",
    "Think of it like this:\n",
    "\n",
    "If the embedding for \"cat\" is a certain vector, then the output layer should also understand that same vector means \"cat\".\n",
    "\n",
    "Sharing weights enforces this symmetry: the model learns one set of weights that both understands and generates token representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f7341",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e82bb33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:12.843398Z",
     "iopub.status.busy": "2025-06-07T03:05:12.843119Z",
     "iopub.status.idle": "2025-06-07T03:05:12.863163Z",
     "shell.execute_reply": "2025-06-07T03:05:12.862644Z",
     "shell.execute_reply.started": "2025-06-07T03:05:12.843372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens,context_size):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :] # Get the last token's logits\n",
    "\n",
    "        probas = torch.softmax(logits, dim = -1)\n",
    "\n",
    "        idx_next = torch.argmax(probas, dim = -1, keepdim = True)\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "963f52b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:12.864405Z",
     "iopub.status.busy": "2025-06-07T03:05:12.863930Z",
     "iopub.status.idle": "2025-06-07T03:05:12.879912Z",
     "shell.execute_reply": "2025-06-07T03:05:12.879059Z",
     "shell.execute_reply.started": "2025-06-07T03:05:12.864381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded context: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"Encoded context:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8fdc7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Next, we put the model into .eval() mode, which disables random components like\n",
    "dropout, which are only used during training, and use the generate_text_simple function\n",
    "on the encoded input tensor:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce0d7710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:12.881535Z",
     "iopub.status.busy": "2025-06-07T03:05:12.880778Z",
     "iopub.status.idle": "2025-06-07T03:05:13.741218Z",
     "shell.execute_reply": "2025-06-07T03:05:13.740441Z",
     "shell.execute_reply.started": "2025-06-07T03:05:12.881513Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267,\n",
      "         49706, 43231, 47062, 34657]])\n",
      "Output length: 14\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(model, encoded_tensor, max_new_tokens = 10, context_size = GPT_CONFIG_124M[\"context_length\"]) \n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a746372a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:13.742113Z",
     "iopub.status.busy": "2025-06-07T03:05:13.741932Z",
     "iopub.status.idle": "2025-06-07T03:05:13.746020Z",
     "shell.execute_reply": "2025-06-07T03:05:13.745441Z",
     "shell.execute_reply.started": "2025-06-07T03:05:13.742098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(out[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb99ba8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:13.746843Z",
     "iopub.status.busy": "2025-06-07T03:05:13.746650Z",
     "iopub.status.idle": "2025-06-07T03:05:13.764055Z",
     "shell.execute_reply": "2025-06-07T03:05:13.763284Z",
     "shell.execute_reply.started": "2025-06-07T03:05:13.746828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am Featureiman Byeswickattribute argue logger Normandy Compton analogous'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307fcec0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As we can see, based on the preceding output, the model generated gibberish, which is not\n",
    "at all coherent text. \n",
    "\n",
    "What happened? \n",
    "\n",
    "The reason why the model is unable to produce coherent text is that we haven't trained it yet. \n",
    "\n",
    "So far, we just\n",
    "implemented the GPT architecture and initialized a GPT model instance with initial random\n",
    "weights.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f2a51bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:13.765038Z",
     "iopub.status.busy": "2025-06-07T03:05:13.764867Z",
     "iopub.status.idle": "2025-06-07T03:05:14.614967Z",
     "shell.execute_reply": "2025-06-07T03:05:14.614264Z",
     "shell.execute_reply.started": "2025-06-07T03:05:13.765024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Aeiman Byeswickattributeometer inspector Normandy freezerigrate\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "    return encoded_tensor\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d2bd9b23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.615953Z",
     "iopub.status.busy": "2025-06-07T03:05:14.615700Z",
     "iopub.status.idle": "2025-06-07T03:05:14.620700Z",
     "shell.execute_reply": "2025-06-07T03:05:14.620118Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.615930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82fd45a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.621659Z",
     "iopub.status.busy": "2025-06-07T03:05:14.621458Z",
     "iopub.status.idle": "2025-06-07T03:05:14.748641Z",
     "shell.execute_reply": "2025-06-07T03:05:14.747907Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.621645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits,dim = -1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4a8f192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.750383Z",
     "iopub.status.busy": "2025-06-07T03:05:14.750091Z",
     "iopub.status.idle": "2025-06-07T03:05:14.755964Z",
     "shell.execute_reply": "2025-06-07T03:05:14.755309Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.750358Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0ff7882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.756869Z",
     "iopub.status.busy": "2025-06-07T03:05:14.756597Z",
     "iopub.status.idle": "2025-06-07T03:05:14.775892Z",
     "shell.execute_reply": "2025-06-07T03:05:14.775185Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.756842Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Gathering SerbianFriday\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "314a3e57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.777086Z",
     "iopub.status.busy": "2025-06-07T03:05:14.776788Z",
     "iopub.status.idle": "2025-06-07T03:05:14.799310Z",
     "shell.execute_reply": "2025-06-07T03:05:14.798601Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.777063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([2.3466e-05, 2.0531e-05, 1.1733e-05])\n",
      "Text 2: tensor([4.2794e-05, 1.6248e-05, 1.1586e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfc58229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.800513Z",
     "iopub.status.busy": "2025-06-07T03:05:14.800210Z",
     "iopub.status.idle": "2025-06-07T03:05:14.818577Z",
     "shell.execute_reply": "2025-06-07T03:05:14.817905Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.800490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities:\n",
      " tensor([-10.6600, -10.7936, -11.3531, -10.0591, -11.0276, -11.3658])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2), dim=0))\n",
    "print(\"Log probabilities:\\n\", log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e5b46fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.819636Z",
     "iopub.status.busy": "2025-06-07T03:05:14.819373Z",
     "iopub.status.idle": "2025-06-07T03:05:14.837845Z",
     "shell.execute_reply": "2025-06-07T03:05:14.837179Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.819618Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8765)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11b4ca",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The goal is to make this average log probability as large as possible by optimizing the model weights.\n",
    "\n",
    "Due to the log, the largest possible value is 0, and we are currently far away from 0.\n",
    "\n",
    "In deep learning, instead of maximizing the average log-probability, it's a standard convention to minimize the negative average log-probability value; in our case, instead of maximizing -10.7722 so that it approaches 0, in deep learning, we would minimize 10.7722 so that it approaches 0.\n",
    "\n",
    "The value negative of -10.7722, i.e., 10.7722, is also called cross-entropy loss in deep learning.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "88827ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.838890Z",
     "iopub.status.busy": "2025-06-07T03:05:14.838670Z",
     "iopub.status.idle": "2025-06-07T03:05:14.855958Z",
     "shell.execute_reply": "2025-06-07T03:05:14.855197Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.838871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8765)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c2de412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.857088Z",
     "iopub.status.busy": "2025-06-07T03:05:14.856826Z",
     "iopub.status.idle": "2025-06-07T03:05:14.872074Z",
     "shell.execute_reply": "2025-06-07T03:05:14.871379Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.857067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9276589",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Note that the targets are the token IDs, which also represent the index positions in the logits tensors that we want to maximize.\n",
    "    \n",
    "The cross_entropy function in PyTorch will automatically take care of applying the softmax and log-probability computation internally over those token indices in the logits that are to be maximized\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e6caf587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.873254Z",
     "iopub.status.busy": "2025-06-07T03:05:14.872861Z",
     "iopub.status.idle": "2025-06-07T03:05:14.900307Z",
     "shell.execute_reply": "2025-06-07T03:05:14.899514Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.873232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8765)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308fef8",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe6ba1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "A concept related to the cross-entropy loss is the perplexity of an LLM.\n",
    "\n",
    "The perplexity is simply the exponential of the cross-entropy loss.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8e88a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.901179Z",
     "iopub.status.busy": "2025-06-07T03:05:14.900968Z",
     "iopub.status.idle": "2025-06-07T03:05:14.914467Z",
     "shell.execute_reply": "2025-06-07T03:05:14.913609Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.901162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52918.7773)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f7f52e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The perplexity is often considered more interpretable because it can be understood as the effective vocabulary size that the model is uncertain about at each step (in the example above, that'd be 52918.7734 words or tokens).\n",
    "\n",
    "In other words, perplexity provides a measure of how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset.\n",
    "    \n",
    "Similar to the loss, a lower perplexity indicates that the model predictions are closer to the actual distribution\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5773d6",
   "metadata": {},
   "source": [
    "### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a004480",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
    "\n",
    "The reasons are:\n",
    "\n",
    "You can run the code examples in a few minutes on a laptop computer without a suitable GPU.\n",
    "\n",
    "The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes.\n",
    "    \n",
    "We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights or bloating the repository size.\n",
    "    \n",
    "For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n",
    "\n",
    "At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately 30 dollars. \n",
    "\n",
    "So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * 30 = 690,000 dollars\n",
    "\n",
    "Below, we use the same dataset we used in chapter 2.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f787ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.915782Z",
     "iopub.status.busy": "2025-06-07T03:05:14.915505Z",
     "iopub.status.idle": "2025-06-07T03:05:14.931900Z",
     "shell.execute_reply": "2025-06-07T03:05:14.931174Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.915758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45e5e4e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:14.932960Z",
     "iopub.status.busy": "2025-06-07T03:05:14.932729Z",
     "iopub.status.idle": "2025-06-07T03:05:15.021949Z",
     "shell.execute_reply": "2025-06-07T03:05:15.021232Z",
     "shell.execute_reply.started": "2025-06-07T03:05:14.932941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = \"/kaggle/input/datase/Harry Potter and The Half-Blood Prince.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "47e7d23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:15.022871Z",
     "iopub.status.busy": "2025-06-07T03:05:15.022662Z",
     "iopub.status.idle": "2025-06-07T03:05:15.027832Z",
     "shell.execute_reply": "2025-06-07T03:05:15.027162Z",
     "shell.execute_reply.started": "2025-06-07T03:05:15.022856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly nor'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34897960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:15.028832Z",
     "iopub.status.busy": "2025-06-07T03:05:15.028515Z",
     "iopub.status.idle": "2025-06-07T03:05:15.046860Z",
     "shell.execute_reply": "2025-06-07T03:05:15.046151Z",
     "shell.execute_reply.started": "2025-06-07T03:05:15.028808Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'his forehead.\\n\\nâ€œI know he will.â€\\n\\nThe scar had not pained Harry for nineteen years. All was well.\\n\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[-99:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f5ae4a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:15.048069Z",
     "iopub.status.busy": "2025-06-07T03:05:15.047847Z",
     "iopub.status.idle": "2025-06-07T03:05:15.865416Z",
     "shell.execute_reply": "2025-06-07T03:05:15.864589Z",
     "shell.execute_reply.started": "2025-06-07T03:05:15.048053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_character = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa7a8616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:15.866544Z",
     "iopub.status.busy": "2025-06-07T03:05:15.866291Z",
     "iopub.status.idle": "2025-06-07T03:05:15.870802Z",
     "shell.execute_reply": "2025-06-07T03:05:15.869934Z",
     "shell.execute_reply.started": "2025-06-07T03:05:15.866518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 6285449\n",
      "Tokens: 1669303\n"
     ]
    }
   ],
   "source": [
    "print(\"Characters:\", total_character)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f2c4675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:15.871931Z",
     "iopub.status.busy": "2025-06-07T03:05:15.871687Z",
     "iopub.status.idle": "2025-06-07T03:05:17.303182Z",
     "shell.execute_reply": "2025-06-07T03:05:17.302398Z",
     "shell.execute_reply.started": "2025-06-07T03:05:15.871910Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 8, \n",
    "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124M[\"context_length\"] , \n",
    "    shuffle = True, \n",
    "    drop_last = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size = 8, \n",
    "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride = GPT_CONFIG_124M[\"context_length\"] , \n",
    "    shuffle = False, \n",
    "    drop_last = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"Number of batches in train loader:\", len(train_loader))\n",
    "print(\"Number of batches in validation loader:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f98caf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:17.372343Z",
     "iopub.status.busy": "2025-06-07T03:05:17.372151Z",
     "iopub.status.idle": "2025-06-07T03:05:17.426427Z",
     "shell.execute_reply": "2025-06-07T03:05:17.425695Z",
     "shell.execute_reply.started": "2025-06-07T03:05:17.372328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 1501184\n",
      "Validation tokens: 167424\n",
      "All tokens: 1668608\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for x, y in train_loader:\n",
    "    train_tokens += x.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for x, y in val_loader:\n",
    "    val_tokens += x.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52e924a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:17.427438Z",
     "iopub.status.busy": "2025-06-07T03:05:17.427207Z",
     "iopub.status.idle": "2025-06-07T03:05:17.433013Z",
     "shell.execute_reply": "2025-06-07T03:05:17.432332Z",
     "shell.execute_reply.started": "2025-06-07T03:05:17.427422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches = None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e506e2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:17.434011Z",
     "iopub.status.busy": "2025-06-07T03:05:17.433770Z",
     "iopub.status.idle": "2025-06-07T03:05:17.449715Z",
     "shell.execute_reply": "2025-06-07T03:05:17.449060Z",
     "shell.execute_reply.started": "2025-06-07T03:05:17.433992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"hiu\")\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07a7f7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:05:17.450742Z",
     "iopub.status.busy": "2025-06-07T03:05:17.450466Z",
     "iopub.status.idle": "2025-06-07T03:08:16.640745Z",
     "shell.execute_reply": "2025-06-07T03:08:16.640158Z",
     "shell.execute_reply.started": "2025-06-07T03:05:17.450717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.997598331914592\n",
      "Validation loss: 10.980638201643782\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "42b9799e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:08:16.641817Z",
     "iopub.status.busy": "2025-06-07T03:08:16.641565Z",
     "iopub.status.idle": "2025-06-07T03:08:16.646502Z",
     "shell.execute_reply": "2025-06-07T03:08:16.645621Z",
     "shell.execute_reply.started": "2025-06-07T03:08:16.641791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5c11a577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:08:16.647510Z",
     "iopub.status.busy": "2025-06-07T03:08:16.647275Z",
     "iopub.status.idle": "2025-06-07T03:08:16.667900Z",
     "shell.execute_reply": "2025-06-07T03:08:16.667143Z",
     "shell.execute_reply.started": "2025-06-07T03:08:16.647495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=100, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a885f24",
   "metadata": {},
   "source": [
    "# TRAINING LOOP FOR THE LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0e32363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:08:16.669259Z",
     "iopub.status.busy": "2025-06-07T03:08:16.668806Z",
     "iopub.status.idle": "2025-06-07T03:08:16.695040Z",
     "shell.execute_reply": "2025-06-07T03:08:16.694480Z",
     "shell.execute_reply.started": "2025-06-07T03:08:16.669242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, device, optimizer, num_epochs,\n",
    "    eval_freq, eval_iter, start_context,tokenizer):\n",
    "\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a6ef280c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T03:08:16.695947Z",
     "iopub.status.busy": "2025-06-07T03:08:16.695764Z",
     "iopub.status.idle": "2025-06-07T05:31:53.395528Z",
     "shell.execute_reply": "2025-06-07T05:31:53.394788Z",
     "shell.execute_reply.started": "2025-06-07T03:08:16.695932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.342, Val loss 10.314\n",
      "Ep 1 (Step 000080): Train loss 5.934, Val loss 5.959\n",
      "Ep 1 (Step 000160): Train loss 5.488, Val loss 5.566\n",
      "Ep 1 (Step 000240): Train loss 5.205, Val loss 5.348\n",
      "Ep 1 (Step 000320): Train loss 5.022, Val loss 5.193\n",
      "Ep 1 (Step 000400): Train loss 4.867, Val loss 5.086\n",
      "Ep 1 (Step 000480): Train loss 4.762, Val loss 4.992\n",
      "Ep 1 (Step 000560): Train loss 4.648, Val loss 4.897\n",
      "Ep 1 (Step 000640): Train loss 4.592, Val loss 4.830\n",
      "Ep 1 (Step 000720): Train loss 4.474, Val loss 4.773\n",
      "Harry potter was stunned.  â€œIâ€™t youâ€™t youâ€™t youâ€™t youâ€™t think youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t youâ€™t think I\n",
      "Ep 2 (Step 000800): Train loss 4.398, Val loss 4.724\n",
      "Ep 2 (Step 000880): Train loss 4.351, Val loss 4.677\n",
      "Ep 2 (Step 000960): Train loss 4.270, Val loss 4.637\n",
      "Ep 2 (Step 001040): Train loss 4.205, Val loss 4.604\n",
      "Ep 2 (Step 001120): Train loss 4.217, Val loss 4.578\n",
      "Ep 2 (Step 001200): Train loss 4.182, Val loss 4.547\n",
      "Ep 2 (Step 001280): Train loss 4.125, Val loss 4.506\n",
      "Ep 2 (Step 001360): Train loss 4.037, Val loss 4.470\n",
      "Ep 2 (Step 001440): Train loss 3.997, Val loss 4.445\n",
      "Harry potter was stunned.  â€œIâ€™m not,â€ said Harry, â€œIâ€™m not to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be\n",
      "Ep 3 (Step 001520): Train loss 3.988, Val loss 4.416\n",
      "Ep 3 (Step 001600): Train loss 3.933, Val loss 4.406\n",
      "Ep 3 (Step 001680): Train loss 3.897, Val loss 4.385\n",
      "Ep 3 (Step 001760): Train loss 3.851, Val loss 4.364\n",
      "Ep 3 (Step 001840): Train loss 3.841, Val loss 4.337\n",
      "Ep 3 (Step 001920): Train loss 3.766, Val loss 4.325\n",
      "Ep 3 (Step 002000): Train loss 3.761, Val loss 4.310\n",
      "Ep 3 (Step 002080): Train loss 3.714, Val loss 4.290\n",
      "Ep 3 (Step 002160): Train loss 3.675, Val loss 4.280\n",
      "Harry potter was stunned.  â€œIâ€™m not going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be\n",
      "Ep 4 (Step 002240): Train loss 3.680, Val loss 4.265\n",
      "Ep 4 (Step 002320): Train loss 3.636, Val loss 4.262\n",
      "Ep 4 (Step 002400): Train loss 3.602, Val loss 4.244\n",
      "Ep 4 (Step 002480): Train loss 3.561, Val loss 4.236\n",
      "Ep 4 (Step 002560): Train loss 3.534, Val loss 4.214\n",
      "Ep 4 (Step 002640): Train loss 3.507, Val loss 4.200\n",
      "Ep 4 (Step 002720): Train loss 3.464, Val loss 4.196\n",
      "Ep 4 (Step 002800): Train loss 3.471, Val loss 4.190\n",
      "Ep 4 (Step 002880): Train loss 3.431, Val loss 4.173\n",
      "Harry potter was stunned.  â€œIâ€™m not going to be here,â€ said Ron, â€œIâ€™m not going to be in the same time.â€  â€œIâ€™m not to know,â€ said Hermione, â€œIâ€™m not going to be in the castle, but Iâ€™m not going to be able to be able to be in the school.â€  â€œIâ€™m not going to\n",
      "Ep 5 (Step 002960): Train loss 3.382, Val loss 4.166\n",
      "Ep 5 (Step 003040): Train loss 3.317, Val loss 4.165\n",
      "Ep 5 (Step 003120): Train loss 3.341, Val loss 4.174\n",
      "Ep 5 (Step 003200): Train loss 3.284, Val loss 4.159\n",
      "Ep 5 (Step 003280): Train loss 3.266, Val loss 4.148\n",
      "Ep 5 (Step 003360): Train loss 3.225, Val loss 4.148\n",
      "Ep 5 (Step 003440): Train loss 3.239, Val loss 4.137\n",
      "Ep 5 (Step 003520): Train loss 3.214, Val loss 4.126\n",
      "Ep 5 (Step 003600): Train loss 3.176, Val loss 4.107\n",
      "Harry potter was stunned. He was standing in the middle of the room, looking around at the window, but he was sure that he was in the same time.  'What's he doing?' said Ron, looking around at him. 'I'm going to be in the kitchen, he's got to be in the room, he's got back.'  'What?' said Harry.  'I'm going to know,' said Ron, looking up at him. 'I'm going to be\n",
      "Ep 6 (Step 003680): Train loss 3.127, Val loss 4.111\n",
      "Ep 6 (Step 003760): Train loss 3.075, Val loss 4.125\n",
      "Ep 6 (Step 003840): Train loss 3.091, Val loss 4.133\n",
      "Ep 6 (Step 003920): Train loss 3.026, Val loss 4.128\n",
      "Ep 6 (Step 004000): Train loss 3.039, Val loss 4.124\n",
      "Ep 6 (Step 004080): Train loss 3.004, Val loss 4.128\n",
      "Ep 6 (Step 004160): Train loss 2.998, Val loss 4.111\n",
      "Ep 6 (Step 004240): Train loss 2.945, Val loss 4.108\n",
      "Ep 6 (Step 004320): Train loss 2.928, Val loss 4.109\n",
      "Harry potter was stunned. He was very well that he was in the same way that he was in the hospital wing. He was very well, but he was not sure he was in the first time. He was not sure he was in the first time. He had not been able to do it. He had been in the first time since he had been in the school, he had been in the first task. He had been in the world, he had not been able to do it. He had not been\n",
      "Ep 7 (Step 004400): Train loss 2.877, Val loss 4.101\n",
      "Ep 7 (Step 004480): Train loss 2.829, Val loss 4.129\n",
      "Ep 7 (Step 004560): Train loss 2.798, Val loss 4.137\n",
      "Ep 7 (Step 004640): Train loss 2.778, Val loss 4.143\n",
      "Ep 7 (Step 004720): Train loss 2.746, Val loss 4.137\n",
      "Ep 7 (Step 004800): Train loss 2.736, Val loss 4.129\n",
      "Ep 7 (Step 004880): Train loss 2.688, Val loss 4.135\n",
      "Ep 7 (Step 004960): Train loss 2.678, Val loss 4.134\n",
      "Ep 7 (Step 005040): Train loss 2.623, Val loss 4.136\n",
      "Ep 7 (Step 005120): Train loss 2.610, Val loss 4.125\n",
      "Harry potter was stunned.  â€˜Iâ€™m not going to be here,â€™ said Ron, looking alarmed. â€˜Iâ€™ll be able to see you.â€™  â€˜Iâ€™m not going to go,â€™ said Hermione, looking alarmed. â€˜Iâ€™m not going to be in here.â€™  â€˜Iâ€™m going to go and get it,â€™ said Ron, looking at Hermione. â€˜I\n",
      "Ep 8 (Step 005200): Train loss 2.535, Val loss 4.153\n",
      "Ep 8 (Step 005280): Train loss 2.511, Val loss 4.178\n",
      "Ep 8 (Step 005360): Train loss 2.462, Val loss 4.177\n",
      "Ep 8 (Step 005440): Train loss 2.441, Val loss 4.191\n",
      "Ep 8 (Step 005520): Train loss 2.407, Val loss 4.174\n",
      "Ep 8 (Step 005600): Train loss 2.424, Val loss 4.194\n",
      "Ep 8 (Step 005680): Train loss 2.361, Val loss 4.184\n",
      "Ep 8 (Step 005760): Train loss 2.326, Val loss 4.190\n",
      "Ep 8 (Step 005840): Train loss 2.302, Val loss 4.184\n",
      "Harry potter was stunned by the time he had seen in his life.  â€œIâ€™m not going to be in a bit of time,â€ said Dumbledore, looking around at him. â€œIâ€™ve just been wondering whether Iâ€™d just thought Iâ€™d have to do it.â€  â€œIâ€™m not,â€ said Harry, â€œbut Iâ€™m sure youâ€™re not going to be able to use it\n",
      "Ep 9 (Step 005920): Train loss 2.239, Val loss 4.222\n",
      "Ep 9 (Step 006000): Train loss 2.210, Val loss 4.268\n",
      "Ep 9 (Step 006080): Train loss 2.195, Val loss 4.266\n",
      "Ep 9 (Step 006160): Train loss 2.148, Val loss 4.272\n",
      "Ep 9 (Step 006240): Train loss 2.124, Val loss 4.269\n",
      "Ep 9 (Step 006320): Train loss 2.075, Val loss 4.279\n",
      "Ep 9 (Step 006400): Train loss 2.057, Val loss 4.280\n",
      "Ep 9 (Step 006480): Train loss 2.007, Val loss 4.272\n",
      "Ep 9 (Step 006560): Train loss 1.986, Val loss 4.271\n",
      "Harry potter was stunned.  â€œIâ€™m not sure youâ€™re in here,â€ said Professor McGonagall, in a very small, â€œbut Iâ€™ve been a very good idea of a very long time. Iâ€™ve got to get a detention for you to. Iâ€™m not sure youâ€™re not a bit more to be glad for you, but Iâ€™ve had a chance of a chance to do it, and Iï¿½\n",
      "Ep 10 (Step 006640): Train loss 1.936, Val loss 4.326\n",
      "Ep 10 (Step 006720): Train loss 1.902, Val loss 4.359\n",
      "Ep 10 (Step 006800): Train loss 1.861, Val loss 4.378\n",
      "Ep 10 (Step 006880): Train loss 1.819, Val loss 4.388\n",
      "Ep 10 (Step 006960): Train loss 1.815, Val loss 4.396\n",
      "Ep 10 (Step 007040): Train loss 1.767, Val loss 4.405\n",
      "Ep 10 (Step 007120): Train loss 1.754, Val loss 4.403\n",
      "Ep 10 (Step 007200): Train loss 1.697, Val loss 4.414\n",
      "Ep 10 (Step 007280): Train loss 1.687, Val loss 4.406\n",
      "Harry potter was stunned by a large amount of tea with a large amount of gold coins around the walls, covered with a large amount of gold coins. The walls were all staring at the ceiling. Harry wondered whether this was a lot of people in the room for the first time, but the only thing he knew was that he was in the first place.  â€œI'm not going to be in the library,â€ he said, and he turned his eyes into a low, â€œI'm not\n",
      "Training completed in 143.61 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, track_tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, device, num_epochs = num_epochs,\n",
    "    optimizer = optimizer, eval_freq = 80, eval_iter = 80,\n",
    "    start_context = \"Harry potter was stunned\", tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "06decc3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T05:31:53.396902Z",
     "iopub.status.busy": "2025-06-07T05:31:53.396439Z",
     "iopub.status.idle": "2025-06-07T05:31:53.401771Z",
     "shell.execute_reply": "2025-06-07T05:31:53.400941Z",
     "shell.execute_reply.started": "2025-06-07T05:31:53.396868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Perplexity: 5.403, Val Perplexity: 81.942\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "train_perplexity = math.exp(train_losses[-1])\n",
    "val_perplexity = math.exp(val_losses[-1])\n",
    "\n",
    "print(f\"Train Perplexity: {train_perplexity:.3f}, Val Perplexity: {val_perplexity:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e957b1b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T05:31:53.402854Z",
     "iopub.status.busy": "2025-06-07T05:31:53.402580Z",
     "iopub.status.idle": "2025-06-07T05:31:55.093832Z",
     "shell.execute_reply": "2025-06-07T05:31:55.092932Z",
     "shell.execute_reply.started": "2025-06-07T05:31:53.402838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, track_tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ea496dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T05:46:27.888573Z",
     "iopub.status.busy": "2025-06-07T05:46:27.888294Z",
     "iopub.status.idle": "2025-06-07T05:46:27.895310Z",
     "shell.execute_reply": "2025-06-07T05:46:27.894461Z",
     "shell.execute_reply.started": "2025-06-07T05:46:27.888555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  \n",
    "            idx_next = torch.multinomial(probs, num_samples=1) \n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1) \n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e16eedcd-a1ae-42be-81e6-6cb531afb65b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T05:48:55.363538Z",
     "iopub.status.busy": "2025-06-07T05:48:55.362927Z",
     "iopub.status.idle": "2025-06-07T05:48:57.132031Z",
     "shell.execute_reply": "2025-06-07T05:48:57.131323Z",
     "shell.execute_reply.started": "2025-06-07T05:48:55.363510Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Harry potter was stunned.\n",
      "\n",
      "Ron and Hermione was standingrofully with fury. This left the changing to the match, Ernie. The little witch and hugged her mouth shut behind them. She dropped Ronâ€™s new robes on top of his robes.\n",
      "\n",
      "â€œSorry, but youâ€™re in ten seconds â€”â€ The girl began Hermione with great difficulty of a huge little fist like sheâ€™s girls.\n",
      "\n",
      "There was a loud, and she sat down the deserted corridor and\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Harry potter was stunned\", tokenizer).to(device),\n",
    "    max_new_tokens=100,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.2\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280243d-2417-4ae1-881e-760f53784fbc",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7607433,
     "sourceId": 12084801,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
